{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "from pprint import pprint\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def d3_d2(d3):\n",
    "    d2 = []\n",
    "    for i in range(len(d3)):\n",
    "        for j in range(len(d3[i])):\n",
    "                d2.append(d3[i][j])\n",
    "    return d2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load `Iris dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = datasets.load_iris()\n",
    "data_iris = tmp.data\n",
    "target = tmp.target\n",
    "data_train, data_test, target_train, target_test = train_test_split(data_iris, target, test_size=0.2, random_state=75)\n",
    "\n",
    "def sanitize_data(raw,labels): #2d to 3d\n",
    "    indexlabel = np.unique(labels)\n",
    "    \n",
    "    fixed_data = [[] for _ in range(len(indexlabel))]\n",
    "    fixed_label = [[] for _ in range(len(indexlabel))]\n",
    "    for i in range(len(labels)):\n",
    "        fixed_data[labels[i]].append(raw[i])\n",
    "        fixed_label[labels[i]].append(labels[i])\n",
    "    return fixed_data, fixed_label\n",
    "\n",
    "data_train,target_train = sanitize_data(data_train,target_train) #3d\n",
    "data_test,target_test = sanitize_data(data_test, target_test)    #3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDA:\n",
    "    def calc_means(data,debug = False):\n",
    "        ar = (np.array(data))\n",
    "        means = []\n",
    "        means_feature_wise = []\n",
    "        for i in ar:\n",
    "            i = np.array(i)\n",
    "            rows,columns = i.shape\n",
    "            means.append([np.array(np.mean(i, axis=0)) for _ in range(rows)])\n",
    "            means_feature_wise.append(np.array(np.mean(i, axis=0)))\n",
    "        if(debug == True):\n",
    "             print(\"calc_means\\n\")\n",
    "             print(\"array data\\n\",ar)\n",
    "             print(\"rows and col\",rows,columns)\n",
    "             print(\"Means: \",means)\n",
    "             print(means_feature_wise)\n",
    "        return means, means_feature_wise\n",
    "    def calc_Sjs(data,means,debug = False):\n",
    "         features_number = (len(data[0][0]))\n",
    "         Sw = [[0 for _ in range(features_number)] for _ in range(features_number)]\n",
    "         count = 0\n",
    "         for i in data:\n",
    "            number_of_data = len(i)\n",
    "            i = np.array(i).T\n",
    "            mi = np.array(means[count]).T\n",
    "            # rows,columns = i.shape\n",
    "          \n",
    "            single = (np.dot(i-mi,(i-mi).T))\n",
    "            ith_sj = single/(number_of_data-1)\n",
    "            Sw += (ith_sj)\n",
    "            count+=1\n",
    "         if(debug == True):\n",
    "            print(\"calc_Sj\\n\")\n",
    "            print(number_of_data-1)\n",
    "            print(\"array data\\n\",data)\n",
    "            print(\"array means\\n\",means)\n",
    "            print(\"list of Sw\\n\",Sw)\n",
    "         return Sw\n",
    "    def calc_Swinverse(Sw,debug = False):\n",
    "        Swinverse = np.linalg.inv(Sw)\n",
    "        if(debug == True):\n",
    "            print(\"calc_Swinverse\\n\")\n",
    "            print(\"Sw\\n\",Sw)\n",
    "            print(\"Swinverse\\n\",Swinverse)\n",
    "        return Swinverse\n",
    "    def calc_Sb(data,Sw,means_feature_wise,debug = False):\n",
    "        n,m = Sw.shape\n",
    "        # features = len(data[0][0])\n",
    "        Sb = np.zeros((n,m))\n",
    "        # data = np.array(data) classes*datapoint*features\n",
    "        freq = [len(data[i]) for i in range(len(data))]\n",
    "        total_freq = sum(freq)\n",
    "        mean = 0#[0 for i in range(len(freq))] # == [10.66666667 10.5       ]\n",
    "\n",
    "        for i in range(len(freq)): mean += (freq[i]*means_feature_wise[i])/(total_freq)\n",
    "        for i in range(len(means_feature_wise)):\n",
    "            mj = np.matrix(means_feature_wise[i] - mean)\n",
    "            Sb += (np.multiply(freq[i],(np.dot(mj.T,mj))))\n",
    "        if(debug):\n",
    "            print(\"calc_Sb\\n\")\n",
    "            print(\"data\\n\",data)\n",
    "            print(\"Sw\\n\",Sw)\n",
    "            print(\"Sb\\n\",Sb)\n",
    "        return Sb\n",
    "    def A(Swi,Sb, debug =False):\n",
    "        if(debug) : pprint(np.dot(Swi,Sb))\n",
    "        return np.dot(Swi,Sb)\n",
    "    def eigen_vector(A,reduced_features : int , debug =False):\n",
    "        eigenvalues,eigenvectors = np.linalg.eig(A)\n",
    "        \n",
    "        #sorting according to eigenvalue\n",
    "        idx = eigenvalues.argsort()[::-1]\n",
    "        sortedeigenvalues = eigenvalues[idx]\n",
    "        sortedeigenvectors = [[] for _ in range(len(idx))]\n",
    "        for i in range(0, len(idx)): sortedeigenvectors[i] = eigenvectors[idx[i]]\n",
    "\n",
    "        if(debug == True):\n",
    "            print(\"\\n-> eigen_vector\")\n",
    "            print(\" eigenvalue\\n\",eigenvalues)\n",
    "            print(\" eigenvector\\n\",eigenvectors)\n",
    "            \n",
    "            print(\"sorted eigenvalue\\n\",sortedeigenvalues)\n",
    "            print(\"sorted eigenvector\\n\",sortedeigenvectors)\n",
    "        \n",
    "        return np.array(sortedeigenvectors[0:reduced_features]), np.array(sortedeigenvalues[0:reduced_features])\n",
    "    def feature_reduction(data,vector,debug =False):\n",
    "        reduced = []\n",
    "        for i in data:\n",
    "            u = []\n",
    "            for j in i:\n",
    "                j = np.dot(vector,np.array(j))\n",
    "                u.append(j)\n",
    "            reduced.append(u)\n",
    "        if(debug == True):\n",
    "            print(\"\\n-> feature_reduction\\ndata\\n\")\n",
    "            pprint(data)\n",
    "            pprint(vector)\n",
    "            print(\"after reduction\")\n",
    "            pprint(reduced)\n",
    "        return reduced\n",
    "    def vector(data):\n",
    "        data = (data_train)\n",
    "        means, means_feature_wise = (LDA.calc_means(data))\n",
    "        Sw = (LDA.calc_Sjs(data,means))\n",
    "        Swi = (LDA.calc_Swinverse(Sw))\n",
    "        Sb = (LDA.calc_Sb(data,Sw,means_feature_wise))\n",
    "        A =LDA.A(Swi,Sb)\n",
    "\n",
    "        point = np.array(data_test)\n",
    "        reduced_features = 1\n",
    "        eigenvector ,eigenvalue = (LDA.eigen_vector(A,reduced_features))\n",
    "        return eigenvector\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying `LDA`, getting eigenvector and Projecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvector = LDA.vector(data_train)\n",
    "\n",
    "reduced_data_train = LDA.feature_reduction(data_train,eigenvector)\n",
    "reduced_data_train = d3_d2(reduced_data_train)  #2D\n",
    "target_train = (sum(target_train,[]))           #1D\n",
    "\n",
    "\n",
    "reduced_data_test = LDA.feature_reduction(data_test,eigenvector)\n",
    "reduced_data_test = d3_d2(reduced_data_test) \n",
    "target_test = (sum(target_test,[]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`kNN` after `LDA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with LDA is  1.0\n"
     ]
    }
   ],
   "source": [
    "data_test = np.array(reduced_data_test) #2D\n",
    "target_test = np.array(target_test)     #2D\n",
    "data_test = (data_test.reshape(-1, data_test.shape[-1]))\n",
    "\n",
    "data_test = data_test.real\n",
    "kNN = KNeighborsClassifier(n_neighbors=5)\n",
    "kNN.fit(data_test,target_test)\n",
    "predicted_label = kNN.predict(np.array(data_test))\n",
    "acc = (sum([1 for i in range(len(data_test)) if predicted_label[i] == target_test[i]])) / len(data_test)\n",
    "\n",
    "print(\"Accuracy with LDA is \",acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`kNN` before `LDA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without LDA is  1.0\n"
     ]
    }
   ],
   "source": [
    "data_test = (data_test) \n",
    "data_test = np.array(data_test) #2D\n",
    "target_test = np.array(target_test)     #2D\n",
    "data_test = (data_test.reshape(-1, data_test.shape[-1]))\n",
    "\n",
    "kNN = KNeighborsClassifier(n_neighbors=5)\n",
    "kNN.fit(data_test,target_test)\n",
    "predicted_label = kNN.predict(np.array(data_test))\n",
    "acc = (sum([1 for i in range(len(data_test)) if predicted_label[i] == target_test[i]]))/len(data_test)\n",
    "\n",
    "print(\"Accuracy without LDA is \",acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both are 1.0 , so can't compare here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
